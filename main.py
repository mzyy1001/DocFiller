import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
import os
from middleware.get_col import get_col
from middleware.filter_by_column_index import filter_by_column_index
import random
from tqdm import tqdm


load_dotenv()

client = OpenAI(
    api_key=os.getenv("DEESEEK_API_KEY"),
    base_url="https://api.deepseek.com"  
)

def read_interview(row_index):
    txt_path = f"interview_out/interview_out{row_index+1}.txt"
    with open(txt_path, 'r', encoding='utf-8') as f:
        return f.read()

def extract_row_context(df, row_index, exclude_col_index):
    row = df[df["Row Index"] == row_index]
    examples = []
    for _, r in row.iterrows():
        if r["Column Index"] != exclude_col_index:
            examples.append(f"{r['Column Header']}ï¼š{r['Content']}")
    return "\n".join(examples)

def split_text_by_line(full_text, max_chars=3000):
    """
    å°†æ–‡æœ¬æŒ‰è¡Œåˆ‡åˆ†ï¼Œç¡®ä¿æ¯ä¸€æ®µä¸è¶…è¿‡ max_charsï¼Œå¹¶åœ¨å®Œæ•´è¡Œç»“æŸå¤„æˆªæ–­ã€‚
    """
    lines = full_text.splitlines()
    chunks = []
    current_chunk = ""
    
    for line in lines:
        # é¢„ä¼°åŠ ä¸Šå½“å‰è¡Œåæ˜¯å¦è¶…é™
        if len(current_chunk) + len(line) + 1 <= max_chars:
            current_chunk += line + "\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.rstrip())
            current_chunk = line + "\n"
    
    if current_chunk:
        chunks.append(current_chunk.rstrip())
    
    return chunks



def build_prompt(question, original, full_text):
    return f"""ä»¥ä¸‹æ˜¯ä¸€æ¬¡é‡‡è®¿çš„åŸå§‹æ–‡æœ¬å†…å®¹ï¼ˆå®Œæ•´ï¼‰ï¼š
----------
{full_text}
----------

ç°åœ¨æœ‰é—®é¢˜æ˜¯ï¼š{question}

åœ¨ç»™å‡ºå›ç­”çš„æ—¶å€™æˆ‘è¿˜éœ€è¦å¯¹åº”çš„åŸæ–‡ï¼ŒåŸæ–‡å¯ä»¥æˆªå–çš„æ›´é•¿ä¸€äº›ï¼Œå¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„åŸæ–‡ï¼Œè¢«è§†ä¸ºæ— æ³•è¡¥å……ã€‚

å¦‚æœ{original}ä¸­å·²ç»å‡ºç°è¿‡çš„å†…å®¹ä¸éœ€è¦å†æåŠ,æ³¨æ„å°½é‡ä¸è¦å’Œoriginal æœ‰ä»»ä½•çš„é‡å¤ã€‚

æœ‰æ—¶å€™äººçš„è¯´è¯ä¼šä¸å®Œæ•´ï¼Œæˆ–è€…æœ‰äº›å†…å®¹æ²¡æœ‰è¯´æ¸…æ¥šï¼Œè¿™æ—¶å€™ä½ éœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡å’Œè¯­å¢ƒï¼Œå»æ€è€ƒèƒŒåçš„å«ä¹‰ã€‚

è¯·ä½ åˆ¤æ–­æ˜¯å¦å¯ä»¥æ ¹æ®å·²æœ‰ä¸Šä¸‹æ–‡å’Œè¯­å¢ƒè¡¥å……è¯¥é—®é¢˜çš„å›ç­”ï¼Ÿå¦‚æœå¯ä»¥ï¼Œè¯·ç›´æ¥è¡¥ä¸Šåˆç†å›ç­”å†…å®¹ï¼›

å¦‚æœèƒ½å›ç­”éƒ¨åˆ†å†…å®¹ï¼Œå£°æ˜èƒ½è¡¥å……å“ªäº›éƒ¨åˆ†ï¼Œç„¶ååªå›ç­”è¿™äº›èƒ½è¡¥å……çš„éƒ¨åˆ†ï¼Œè€Œä¸éœ€è¦å‘Šè¯‰æˆ‘å“ªäº›ä¸èƒ½å›ç­”ã€‚

æ‰€æœ‰èƒ½æåˆ°çš„å›ç­”ï¼Œå¿…é¡»è¦æœ‰å¯¹åº”çš„åŸæ–‡æ”¯æŒï¼ŒåŸæ–‡å¿…é¡»æ˜¯å®Œæ•´çš„ä¸€å¥è¯ã€‚

å¯ä»¥ä½¿ç”¨ä»¥ä¸‹çš„æ ¼å¼å›ç­”ï¼š
é—®é¢˜ï¼š
å›ç­”ï¼š
åŸæ–‡è¯æ®ï¼š

å¦‚æœä¸èƒ½å›ç­”è¡¥å……ä»»æ„ä¸€ä¸ªé—®é¢˜ï¼Œå³ä½¿æ˜¯ä¸€éƒ¨åˆ†ï¼Œè¯·ä»…å›å¤â€œæˆ‘æ— æ³•è¡¥å……ä»»ä½•å†…å®¹â€ï¼Œè€Œä¸å¸¦æœ‰ä»»ä½•çš„è§£é‡Šã€‚
"""

def ask_deepseek(prompt):
    res = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ±‡æ€»æœºå™¨ï¼Œè´Ÿè´£æ±‡æ€»æ‰€æœ‰çš„å›ç­”å†…å®¹ã€‚å¯ä»¥çœç•¥éƒ¨åˆ†ç¹ççš„è¯æ®å’Œç†ç”±ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    return res.choices[0].message.content

def get_question(question_header, original, row_context):
    """
    ç”¨ AI å°†æ¨¡ç³Šçš„ question_header + row_context å½’çº³å‡ºä¸€ä¸ªæ˜ç¡®çš„é—®é¢˜ã€‚
    """
    prompt = f"""
æˆ‘ä»¬æ­£åœ¨æ•´ç†ä¸€ä»½è°ƒç ”ç»“æœï¼Œå…¶ä¸­è¡Œçš„æ ‡é¢˜æ˜¯ï¼š"{question_header}"ï¼Œ
æˆ‘å½“å‰å·²ç»æœ‰ä¸€ä¸ªä¸å®Œæ•´çš„å›ç­”å†…å®¹æ˜¯ï¼š"{original}"ã€‚å…¶ä¸­ç¼ºä¹çš„å†…å®¹çš„åœ°æ–¹æ ‡è®°äº†â€œå¾…è¡¥å……â€ æˆ–è€… â€œéœ€è¦è¡¥å……â€
å¦‚æœâ€œå¾…è¡¥å……â€å‰åå·²ç»æ˜ç¡®å£°æ˜äº†å“ªäº›å†…å®¹éœ€è¦è¡¥å……ï¼Œè¯·åŒ…å«åœ¨å›ç­”ä¸­ã€‚ï¼ˆæ¯”å¦‚ç¼ºå°‘...éœ€è¦è¡¥å……ï¼‰ï¼Œé‚£ä¹ˆç¼ºå°‘çš„ä¸œè¥¿æ˜¯å¿…é¡»è¦è¢«æé—®çš„ã€‚

ä¸‹é¢æ˜¯å…¶ä»–å—è®¿è€…å¯¹è¿™ä¸€åˆ—å†…å®¹çš„å®Œæ•´å›ç­”å†…å®¹ï¼š
----------
{row_context}
----------

ä½ éœ€è¦å­¦ä¹ å…¶ä»–å—è®¿è€…çš„å›ç­”å†…å®¹ï¼Œç†è§£æˆ‘è¿™ä¸€ä¸ªä¸å®Œæ•´çš„å›ç­”å†…å®¹ç¼ºå°‘äº†ä»€ä¹ˆå†…å®¹ã€‚

è¯·æ ¹æ®è¿™äº›å†…å®¹ï¼Œæ€»ç»“å‡ºä¸å®Œæ•´çš„å›ç­”å†…å®¹ç¼ºå°‘ä»€ä¹ˆå†…å®¹ï¼Œç”¨é—®é¢˜æ¥æè¿°ï¼Œå¯ä»¥æ˜¯ä¸€ä¸ªé—®é¢˜æˆ–è€…å¤šä¸ªé—®é¢˜.
é—®é¢˜å°½é‡ä¸è¦è¿‡äºå…·ä½“ï¼Œè€Œç»™æ›´å¤šå›ç­”çš„ç©ºé—´ï¼Œä½†æ˜¯è¦ä¿è¯å‰åæ–‡çš„å…³è”æ€§ã€‚
é—®é¢˜ä¼šè¢«ä½œä¸ºprompt è¿›ä¸€æ­¥ä¼ é€’ç»™ DeepSeek è¿›è¡Œå›ç­”ä¸‹ä¸€ä¸ªé—®é¢˜ã€‚
ä¸è¦å¸¦ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªé—®é¢˜çš„ç†ç”±ï¼ŒåªåŒ…å«é—®é¢˜æœ¬èº«å°±å¥½äº†ã€‚
"""

    # å‘ DeepSeek å‘é€è¯·æ±‚
    res = client.chat.completions.create(
        model="deepseek-chat",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå¸®åŠ©æç‚¼å…·ä½“è°ƒæŸ¥é—®é¢˜çš„åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    
    question = res.choices[0].message.content.strip()
    return question


def ask_deepseek_multi(full_text,question_header, original, row_context, log_file):
    """
    å¯¹åˆ†æ®µåçš„æ–‡æœ¬é€æ®µæé—®ï¼Œè®°å½•æ¯æ®µçš„å“åº”ã€‚
    æ”¶é›†æ‰€æœ‰éâ€œæ— æ³•è¡¥å……â€çš„å›ç­”ï¼Œæœ€ç»ˆåˆå¹¶è¿”å›ã€‚
    """
    chunks = split_text_by_line(full_text)
    valid_answers = []
    question = get_question(question_header, original, row_context)
    with open(log_file, "w", encoding="utf-8") as log:
        log.write(f"ğŸ” é—®é¢˜ï¼š{question}\n")
        for i, chunk in enumerate(tqdm(chunks, desc="ğŸ” æ­£åœ¨ç”ŸæˆæŠ¥å‘Š")):

            
            prompt = build_prompt(question, original, chunk)
            result = ask_deepseek(prompt)

            log.write(f"ğŸ¤– AI Response {i+1}:\n{result}\n")
            log.write(f"{'-'*80}\n\n")

            simplified = result.strip().replace("ã€‚", "").replace(" ", "")
            valid = simplified != "æˆ‘æ— æ³•è¡¥å……ä»»ä½•å†…å®¹"
            if valid:
                valid_answers.append(f"(From Part {i+1})\n{result.strip()}")
            tqdm.write(f"âœ… Chunk {i+1} processed, valid answer: {valid}")

    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå›ç­”ï¼Œè¿”å›é»˜è®¤æ¶ˆæ¯
    if valid_answers:
        return "\n\n".join(valid_answers)
    else:
        return "æˆ‘æ— æ³•è¡¥å……ä»»ä½•å†…å®¹"


def main():

    
    
    df = pd.read_csv("todo_list.csv")
    full_output = []
    preview_output = []
    for i in range(1, 100):
        
        txt_path = f"interview_out/interview_out{i}.txt"
        if not os.path.exists(txt_path):
            continue
        print(f"Processing {i}th interview...")
        # col_idx = get_col(txt_path, "output.csv")
        col_idx = get_col(txt_path, "output.csv")
        print(f"Predicted Column Index: {col_idx}")
        relevant_rows = filter_by_column_index("todo_list.csv", col_idx)
        #print(relevant_rows)
        for _, row in relevant_rows.iterrows():
            print(f"Processing row: {row['Row Index']}, column: {col_idx}'s content...")
            row_idx = int(row["Row Index"])
            folder = f"result/row{row_idx}_col{col_idx}"
            os.makedirs(folder, exist_ok=True)  
            column_header = row["Column Header"]
            question_header = row["Row Header"]
            original = row["Content"]

            full_text = read_interview(i - 1)
            this_row = df[df["Row Index"] == row_idx]
            other_columns = this_row[this_row["Column Index"] != col_idx]
            sampled = other_columns.sample(n=min(3, len(other_columns)), random_state=42)
            row_context = ""
            for _, r in sampled.iterrows():
                row_context += f"{r['Column Header']}ï¼š{r['Content']}\n"
            chunk_log_path = os.path.join(folder, "chunk_log.txt")
            build_prompt_text = ask_deepseek_multi(full_text, question_header, original, row_context, chunk_log_path)
            res = ask_deepseek(build_prompt_text)
            preview_output.append({
                "interview_file": txt_path,
                "Predicted Column Index": col_idx,
                "Row Index": row_idx,
                "Column Header": column_header,
                "Question Header": question_header,
                "Original Content": original,
                "Row Context": row_context,
                "AI Completion": res
            })
            
            with open(os.path.join(folder, "completion.txt"), "w", encoding="utf-8") as f:
                for item in preview_output:
                    f.write(f"ğŸ§¾ Header: {item['Column Header']}\n")
                    f.write(f"â“ Question Header: {item['Question Header']}\n")
                    f.write(f"ğŸ¤– AI Completion:\n{item['AI Completion']}\n")
                    f.write("-" * 60 + "\n\n")         
            preview_output.clear()  
        
                    

if __name__ == "__main__":
    main()
